{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pyGoodVibes-streamlit-final.ipynb","provenance":[{"file_id":"1JK-DfHyNxbk7K3fHjjDA9ouNwRzH-cLl","timestamp":1632394710154},{"file_id":"1LLo0LI3h81iqcZd3dSva_y0b1WbGnYVO","timestamp":1630531036087},{"file_id":"1oOhIL99tVmJkthK5XvbEeSGNSdv4iTXF","timestamp":1630524859957}],"collapsed_sections":["jdDA_Nv9_imk"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"bK_SbUJh3-GS"},"source":["authors:\n","- Christophe Gauffre (linkedin: /christophegauffre)\n","- Aurélien Nanette( linkedin: /a-nanette)"]},{"cell_type":"markdown","metadata":{"id":"gHq_aGtjM4vI"},"source":["# Build du projet"]},{"cell_type":"markdown","metadata":{"id":"Qpk7jv5k6zSn"},"source":["## Installation de base"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDU-1dn16xGf","executionInfo":{"status":"ok","timestamp":1633380707090,"user_tz":-120,"elapsed":15913,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"9a19c409-6994-4abb-a545-48eb2ece0863"},"source":["from google.colab import drive\n","import os\n","import pathlib\n","import time\n","\n","drive.mount(\"/content/gdrive\", force_remount=False)\n","\n","! pip install -q kaggle\n","! pip install -q plotly --upgrade\n","! pip install -q streamlit-wordcloud\n","! pip install -qq streamlit\n","! pip install -qq pyngrok"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"stNB6y-C-1ko"},"source":["## chargement des données et préparation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8fMAY-R7Vz7","executionInfo":{"status":"ok","timestamp":1633380732418,"user_tz":-120,"elapsed":20219,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"044ab3a3-c7ed-464b-fd5d-3586133ca7d4"},"source":["t0 = time.time()\n","#si les données ne sont pas sur le drive, les télécharger de Kaggle. Fichier d'autentif dans le drive\n","os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\" # dossier drive où a été stocké préalablement le fichier json kaggle de credentials\n","data_dir = pathlib.Path('dataset')\n","\n","# téléchargement des données\n","! kaggle datasets download -d daisukelab/dc2020task2 #--force # force pour force le téléchargement\n","# unzip des données\n","! unzip -q dc2020task2.zip -d dataset # unzip dans le dossier 'dataset' de la VM google\n","\n","t1 = time.time()\n","print(\"telechargement et unzip effectuée en {:d}mn et {:d}s\".format(int((t1-t0)/60),int((t1-t0)%60)))\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["dc2020task2.zip: Skipping, found more recently modified local copy (use --force to force download)\n","replace dataset/ToyCar/test/anomaly_id_01_00000000.wav? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n","telechargement et unzip effectuée en 0mn et 20s\n"]}]},{"cell_type":"markdown","metadata":{"id":"hChk5Jb1_v_Z"},"source":["## Script main.py"]},{"cell_type":"code","metadata":{"id":"cfCrFKS1Ea8r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633380733386,"user_tz":-120,"elapsed":15,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"b7a50acb-f9fb-4e6b-fc48-19e1ca961aac"},"source":["%%writefile streamlit_toolbox.py\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","import streamlit as st\n","import time\n","\n","def get_anomaly(file_path):\n","  \"\"\"\n","  dans le cadre du dataset https://www.kaggle.com/daisukelab/dc2020task2\n","  retourne la classe d'anomalie du fichier son en fonction du nom du fichier\n","  :param file_path: chemin vers le fichier son étudié\n","  :return: int: label -  0 / 1: sans anomalie/avec anomalie\n","  \"\"\"\n","  parts = file_path.split(os.path.sep)\n","  anomaly = parts[-1].split('_')[0]\n","  if anomaly == 'anomaly':\n","      return 'oui'\n","  else:\n","      return 'non'\n","\n","def get_machine_id(file_path):\n","  \"\"\"\n","  dans le cadre du dataset https://www.kaggle.com/daisukelab/dc2020task2\n","  retourne la machine concernée par le fichier\n","  :param file_path: chemin vers le fichier son étudié\n","  :return: str: nom de la machine\n","  \"\"\"\n","  parts = file_path.split(os.path.sep)\n","  machine_id = parts[1] + '_' + parts[3].split('_')[-2]\n","  return machine_id\n","\n","@st.cache\n","def select_inputfile(data_dir, selected_machines):\n","  \"\"\"\n","  méthode de chargement des fichiers, en fonction des type de machines analysées.\n","\n","  :param data_dir: directory ou sont enregistrés les fichiers\n","  :param selected_machines: liste de type de machine à étudier\n","  :return: une dataframe, ainsi que la liste de fichiers train, liste  de fichiers test, liste des type de machine différents, liste de machines différentes,\n","  dictionnaire des données type/machine/fichier de train et de test\n","  \"\"\"\n","  df  = pd.DataFrame(columns=[\"fichier\",\"type\",\"set\",\"anomalie\"])\n","\n","  files_train = []\n","  files_test = []\n","  for m in selected_machines:\n","      mach_files_train = pd.DataFrame(tf.io.gfile.glob(str(data_dir) + '/'+m+'/train/*'),columns=['fichier'])\n","      mach_files_train['type']=m\n","      mach_files_train['set']='train'\n","      df = df.append(mach_files_train,ignore_index=True)\n","\n","      mach_files_test = pd.DataFrame(tf.io.gfile.glob(str(data_dir) + '/'+m+'/test/*'),columns=['fichier'])\n","      mach_files_test['type']=m\n","      mach_files_test['set']='test'\n","      df = df.append(mach_files_test,ignore_index=True)\n","\n","      files_train.extend(mach_files_train.fichier)\n","      files_test.extend(mach_files_test)\n","\n","  machine_list = df['type'].unique()\n","  df['machine'] = df.fichier.map(get_machine_id)\n","  df['anomalie'] = df.fichier.map(get_anomaly)\n","  machine_id_list = df['machine'].unique()\n","\n","  machine_train_dict = {}\n","  machine_test_dict={}\n","\n","  for m in machine_list:\n","      machine_train_dict[m]={}\n","      machine_test_dict[m] = {}\n","      for id in set(df[df['type']==m].machine):\n","          machine_train_dict[m][id] = df[(df['type']== m) & (df['machine']==id)].fichier\n","    \n","  return df,machine_list,machine_id_list,machine_train_dict,machine_test_dict\n","\n","import cv2 as cv\n","import urllib.request\n","import ssl\n","import numpy as np\n","#import toolbox2 as tb2\n","\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","def url_to_image(url):\n","  resp = urllib.request.urlopen(url)\n","  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","  imageBGR = cv.imdecode(image, cv.IMREAD_COLOR)\n","  imageRGB = cv.cvtColor(imageBGR , cv.COLOR_BGR2RGB)\n","  return imageRGB\n","\n","def resize(image,size):\n","  return cv.resize(image,size,interpolation = cv.INTER_AREA)\n","\n","#@st.cache\n","def init_toolbox(machine_list,machine_id_list,spec_size=(512,256)):\n","  tb2.machine_list = machine_list\n","  tb2.machine_id_list = machine_id_list\n","  tb2.spectro_size=spec_size\n","\n","# @st.cache\n","# def transform_data_train(mach, machine_train_dict):\n","#   return tb2.prepare_data_train(mach, machine_train_dict)\n","\n","# @st.cache(allow_output_mutation=True,suppress_st_warning=True)\n","# def createData(files, verbose=1):\n","#   tb2.spectro_size=(512,256)\n","#   with st.empty():\n","#       if verbose:\n","#         st.spinner(\"création du pipeline de preprocessing des données ...\") \n","#       t0 = time.time()\n","#       dataset = tf.data.Dataset.from_tensor_slices(files)\n","#       dataset = dataset.map(tb2.get_waveform_and_label_and_machine_id_and_anomaly, num_parallel_calls=tb2.AUTOTUNE)\n","#       dataset = dataset.map(tb2.get_spectrogram_and_label_and_machine_id_and_anomaly, num_parallel_calls=tb2.AUTOTUNE).batch(len(files)) #.batch(1000)\n","\n","#       if verbose:\n","#           st.spinner(\"création des données...\")\n","#       X, label,machine,anomaly = next(iter(dataset)) #bien faire un batch de la longueur voulue\n","\n","#       t1 = time.time()\n","#       if verbose:\n","#           st.spinner(\"génération des spectrogrammes de {:d} fichiers en {:.2f}s (temps moyen de {:.3f}ms par fichier)\".format(len(files),t1-t0,(t1-t0)/(len(files))*1000))\n","\n","#   return X,label,machine,anomaly\n","\n","from keras import backend as K\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Flatten\n","from tensorflow.keras.models import Model, Sequential, load_model\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","\n","def createModel():\n","    \"\"\"\n","    Cette méthode crée le modème d'encodage des spectros\n","    :return: Sequential model\n","    \"\"\"\n","\n","    model = Sequential()\n","    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=[512,256,1]))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu')) # tests à 128\n","    model.add(Dropout(0.2))\n","    model.add(Dense(128)) # test à 64 un peu moins performant\n","\n","    return model\n","\n","   \n","\n","\n","\n","@st.cache(allow_output_mutation=True)\n","def loadModel(file):\n","  \"\"\"\n","    méthode de chargement d'un modèle préentraîné, enregistré sur disque\n","    :param file: chemin d'accès au fichier  de poids\n","    :return: modèle préentraîné\n","  \"\"\"\n","  session = K.get_session()\n","  model = createModel()\n","  model.load_weights(file)\n","  return model,session\n","\n","@st.cache(hash_funcs={tf.keras.models.Sequential: lambda model: model.get_config()})\n","def encode_train(model,data,session):\n","  encoded = model.predict(data)\n","  return encoded\n","\n","@st.cache(hash_funcs={tf.keras.models.Sequential: lambda model: model.get_config()})\n","def encode_test(model,data,session):\n","  encoded = model.predict(data)\n","  return encoded\n","\n","\n","@st.cache\n","def  get_data(file,index=None,cols=None):\n"," df = pd.read_csv(file,index_col=index,usecols=cols)\n"," return df\n","\n","@st.cache\n","def get_data_LOF():\n","  return pd.read_csv('/content/gdrive/MyDrive/Datascientest/PROJET/PyGoodVibes/STREAMLIT/final_LOF_results.csv',index_col=0)\n","@st.cache\n","def get_data_SVM():\n","  return pd.read_csv('/content/gdrive/MyDrive/Datascientest/PROJET/PyGoodVibes/STREAMLIT/final_SVM_results.csv',index_col=0)\n"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting streamlit_toolbox.py\n"]}]},{"cell_type":"code","metadata":{"id":"EmVNXz9aVll8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633381036074,"user_tz":-120,"elapsed":562,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"fd8857dd-6513-48e5-aed3-a30b7017349f"},"source":["%%writefile app.py\n","import streamlit_toolbox as tb\n","import streamlit as st\n","import tensorflow as tf\n","from keras import backend as K\n","import keras\n","import os\n","import pathlib\n","import pandas as pd\n","import numpy as np\n","import librosa\n","import librosa.display\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import seaborn as sns\n","from sklearn.decomposition import PCA\n","import time\n","\n","import streamlit_wordcloud as wordcloud\n","\n","class my_app():\n","\n","  def __init__(self):\n","\n","    # self.px_color = px.colors.qualitative.spectro2 # TODO\n","    # self.px_color = px.colors.qualitative.G10\n","    self.px_color = px.colors.qualitative.Set2\n","\n","    sns.set() # Use seaborn's default style to make attractive graphs\n","    plt.rcParams['figure.dpi'] = 100 # \n","    \n","    self.data_dir = pathlib.Path('dataset')\n","    self.available_machines = tf.io.gfile.listdir(str(self.data_dir))\n","    \n","    self.root_path = \"/content/gdrive/MyDrive/git/pyGoodVibes/\"\n","    self.toycar_test_pred_v2 = pd.read_csv(self.root_path+'data/toycar_prediction_v2.csv')\n","\n","    self.df = pd.read_csv(self.root_path+'final_encoded_machine_dataset.csv',usecols=['fichier','type','set','machine','anomalie'])\n","    if 'fichier' not in self.df.columns:\n","        self.df = self.df.reset_index()\n","        self.df = self.df.rename(index={0:'fichier'})\n","\n","    self.machine_list = self.df['type'].unique()\n","    self.machine_id_list = self.df.machine.unique()\n","\n","    #tb.init_toolbox(self.machine_list,self.machine_id_list)\n","\n","    nom_final = self.root_path+'final__weight_encoder_model_machine.h5'\n","    self.encoder, session = tb.loadModel(nom_final)\n","\n","    st.image(f\"{self.root_path}images/main_banner.png\")\n","\n","    st.sidebar.title(\"pyGoodVibes\\n\")\n","    st.sidebar.title(\"Menu\\n\")\n","\n","    menu = [\"Le projet\",\"Les données\",\"Modélisation\",\"Résultats & Perspectives\",\"A propos\"]\n","    self.choice = st.sidebar.selectbox(\"\", menu,index = 0)\n","\n","    if self.choice == 'Le projet':\n","      self.chapitre_choice = self.chapter_selection_on_sidebar([\"Résumé\",\n","                                                                \"Contexte\",\n","                                                                \"Progression\",\n","                                                                \"Résultats et Perspectives\"])\n","      self.le_projet()\n","\n","    elif self.choice == 'Les données':\n","      self.sous_menu_donnees = [\"Première exploration de données\",\"Visualisation des données audio\",\"Visualisation temps-fréquence\"]\n","      self.chapitre_choice = self.chapter_selection_on_sidebar(self.sous_menu_donnees)\n","      self.machine_selection_on_sidebar()\n","      self.les_donnees()\n","\n","    elif self.choice == \"Modélisation\":\n","      self.modelisation_chapters = [\"intro - objectifs\",\n","                                \"fonction de perte\",\n","                                \"architecture\",\n","                                \"résultats de l'encodage\",\n","                                \"discrimination des anomalies\",\n","                                \"détection non supervisée des anomalies\"]\n","      self.chapitre_choice = self.chapter_selection_on_sidebar(self.modelisation_chapters)\n","      self.machine_selection_on_sidebar()\n","      self.modelisation()\n","    elif self.choice == \"Résultats & Perspectives\":\n","      self.machine_selection_on_sidebar()\n","      self.resultats()\n","    elif self.choice == \"A propos\":\n","      self.a_propos()\n","    \n","    elif choice == \"Biblio\":\n","      self.biblio()\n","\n","\n","  def chapter_selection_on_sidebar(self,chapters_list):\n","      # chapters_list = [\"Résumé\",\"Contexte\",\"Progression\",\"Résultats et Perspectives\"]\n","      with st.sidebar:\n","        chapitre_choice = st.radio(\"chapitre\",chapters_list)\n","      return chapitre_choice\n","\n","\n","  def machine_selection_on_sidebar(self):\n","    with st.sidebar.form(key ='Form1'):\n","      if 'selected_machines' not in st.session_state:\n","        st.session_state.selected_machines = [\n","                                              self.machine_list[0],\n","                                              self.machine_list[1],\n","                                              self.machine_list[2],\n","                                              self.machine_list[3],\n","                                              self.machine_list[4],\n","                                              self.machine_list[5],\n","                                              ]\n","      self.selected_machine = st.multiselect('Type de machines testées',self.machine_list,key='selected_machines',help='filtre les données affichées') #default=[self.available_machines[i] for i in np.random.choice(range(len(self.available_machines)),np.random.randint(1,len(self.available_machines),1)[0],replace=False)]\n","      submit_button = st.form_submit_button(label='appliquer', help='applique le nouveau filtre')\n","\n","    self.update_sample = st.sidebar.button(\"update\",on_click=self.update_samples, help=\"génére de nouveaux tirages aléatoire de données\")\n","    self.df = self.df[self.df.type.isin(self.selected_machine)]\n","    self.df_train = self.df[self.df.set==\"train\"]\n","    self.df_test = self.df[self.df.set==\"test\"]\n","\n","  def le_projet(self):\n","\n","    if self.chapitre_choice == \"Résumé\":\n","      self.projet_resume()\n","\n","    if self.chapitre_choice == \"Contexte\":\n","      self.projet_context()\n","\n","    if self.chapitre_choice == \"Progression\":\n","      self.projet_progression()\n","\n","    if self.chapitre_choice == \"Résultats et Perspectives\":\n","      self.choice == \"Résultats & Perspectives\"\n","      self.machine_selection_on_sidebar()\n","      self.resultats()\n","\n"," \n","  def projet_resume(self):\n","    st.markdown(\n","        \"\"\"\n","        \\#AnormalyDetection \\#Spectrogramme \\#DeepLearning \\#Encoder \\#ACP \\#LOF\n","\n","        Ce Projet a pour but de **détecter des sons anormaux**, sur des échantillons de 10s enregistrés en condition réelle, à l'aide d'un algorithme d'**apprentissage non supervisé**.\n","\n","        Plusieurs types de machines ayant des **signatures sonores** très différentes les unes des autres vont constituer notre jeu de données, et comme en condition réelle,\n","        *seuls les sons normaux vont participer à l'apprentissage du modèle*.\n","\n","        Lors des phases d'apprentissage et de prédiction (détection d'anormalité), les échantillons sonores sont transformés en **spectrogrammes** pour alimenter le modèle.\n","\n","        Après plusieurs itérations, notre choix s'est tourné vers l'utilisation d'un modèle de **deep learning** construit sur la base d'un **encoder**, complété d'une **Analyse en Composantes Principales** (ACP),\n","        pour la partie *feature engineering* (extraction l'information pertinente des spectrogrammes) et d'un **Local Outlier Factor** (LOF) pour la partie *outlier detection*.\n","\n","\n","        Alors que la différenciation entre sons normaux et anormaux est **quasi imperceptible à l'oreille humaine**, les performances de l'algorithme sont très bonnes sur la moitiés des machines testées!\n","\n","        \"\"\"\n","    )\n","    st.image(f\"{self.root_path}/images/model_v3.png\",caption=\"schéma du pipeline complet\")\n","\n","\n","  def word_cloud_st(self):\n","    words = [\n","        dict(text = \"sons anormaux\", value = 10, commentaire = \"\"),\n","        dict(text = \"détection précoce\", value = 10, commentaire = \"\"),\n","        dict(text = \"detection automatique\", value = 10, commentaire = \"\"),\n","        dict(text = \"bon marché\", value = 10, commentaire=\"\"),\n","        dict(text = \"industrie 4.0\", value = 10, commentaire = \"L'industrie 4.0 marque le développement d’un système décentralisé, où les processus sont contrôlés et corrigés de façon automatisée et où vous pouvez améliorer les performances des systèmes de production, en tirant parti des nouvelles technologies, et ainsi de les utiliser de manière plus en plus rentable et efficace. Finalement mais pas moins important, l’industrie 4.0 est déterminée à rendre les processus encore plus intelligents, facilitant toujours plus l’utilisation des outils par l’utilisateur.\"),\n","        dict(text = \"smart factory\", value = 10, commentaire = \"La Smart Factory – Usine intelligente – est l'objectif de l'industrie 4.0, où la technologie devient un catalyseur pour obtenir une usine interconnectée, plus intelligente et performante grâce à une meilleure collaboration homme-machine.\"),\n","        dict(text = \"deep learning\", value = 10, commentaire = \"Le deep learning ou apprentissage profond est un type d'intelligence artificielle dérivé du machine learning (apprentissage automatique) où la machine est capable d'apprendre par elle-même, contrairement à la programmation où elle se contente d'exécuter des règles prédéterminées.\"),\n","        dict(text = \"IA\", value = 10, commentaire = \"L'intelligence artificielle (IA) est « l'ensemble des théories et des techniques mises en œuvre en vue de réaliser des machines capables de simuler l'intelligence humaine »\"),\n","        dict(text = \"maintenance prédictive\", value = 10, commentaire = \"La maintenance prédictive consiste à anticiper les défaillances à venir sur un équipement, un objet, un système, etc. Concrètement, il s’agit d’aller au-devant d’une panne ou d’un dysfonctionnement grâce au cumul d'un ensemble de données. En plein essor ces dernières années, la maintenance prédictive permet surtout d’anticiper ces pannes et offre la possibilité d’intervenir en évitant une réparation beaucoup plus coûteuse.\"),\n","        dict(text = \"apprentissage non-supervisé\", value = 10, commentaire = \"L'apprentissage non supervisé désigne la situation d'apprentissage automatique où les données ne sont pas étiquetées. Il s'agit donc de découvrir les structures sous-jacentes à ces données non étiquetées. Puisque les données ne sont pas étiquetées, il est impossible à l'algorithme de calculer de façon certaine un score de réussite. L'absence d'étiquetage ou d'annotation caractérise les tâches d'apprentissage non supervisé et les distingue donc des tâches d'apprentissage supervisé.\"),\n","        dict(text = \"auto-encodeur\", value = 10, commentaire = \"Les auto-encodeurs sont des algorithmes d’apprentissage non supervisé à base de réseaux de neurones artificiels, qui permettent de construire une nouvelle représentation d’un jeu de données. Généralement, celle-ci est plus compacte, et présente moins de descripteurs, ce qui permet de réduire la dimensionnalité du jeu de données. L’architecture d’un auto-encodeur est constitué de deux parties : l’encodeur et le décodeur.\"),\n","        dict(text = \"ASD\", value = 10, commentaire =\"La détection de sons anormaux (Anormalous Sound Detection) est la tâche d'identifier si le son émis par une machine cible est normal ou anormal. La détection automatique des défaillances mécaniques est une technologie essentielle dans la quatrième révolution industrielle, y compris l'automatisation d'usine basée sur l'intelligence artificielle (IA). La détection rapide d'une anomalie de la machine en observant ses sons peut être utile pour la surveillance de l'état de la machine.\"),\n","        dict(text = \"détection d'anomalies\", value = 10, commentaire=\"Le but de la détection d’anomalie est de repérer des données qui ne sont pas conformes à ce à quoi l’on peut s’attendre par rapport aux autres données. Il s’agit, par exemple, de données qui ne suivent pas le même schéma ou qui sont atypiques pour la distribution de probabilité observée. La difficulté du problème provient du fait qu’on ne connait pas au préalable la distribution sous-jacente de l’ensemble des données. C’est à l’algorithme d’apprendre une métrique appropriée pour détecter les anomalies. Parmi les exemples d’applications courantes, citons les transactions bancaires (où une anomalie sera vue comme une fraude potentielle), la surveillance des données physiologiques d’un malade (l’anomalie est un problème de santé possible), ou encore la détection de défauts dans des chaines de production. La détection d’anomalie est souvent un problème d’apprentissage de type non supervisé.\"),\n","        dict(text = \"spectrogramme\", value = 10, commentaire=\"Le spectrogramme est un diagramme représentant le spectre d'un phénomène périodique, associant à chaque fréquence une intensité ou une puissance 1. L'échelle des fréquences et celle des puissances ou intensités peuvent être linéaires ou logarithmiques.\"),\n","        ]\n","    return_obj = wordcloud.visualize(words,\n","                                tooltip_data_fields={\"text\":\"mot-clé\", \"commentaire\":\"\"},\n","                                per_word_coloring=False,\n","                                width = \"100%\",\n","                                height = 900,\n","                                layout = 'archimedean',\n","                                padding = 12,\n","                                )\n","\n","  def projet_context(self):\n","    col1, col2 = st.columns(2)\n","    with col1:\n","      self.word_cloud_st()\n","    with col2:\n","      expander_context = st.expander(\"Contexte\",expanded=True)\n","      with expander_context:\n","          st.markdown(\"\"\"\n","        La **détection de sons anormaux** (ASD - Anomalous Sound Detection) a pour but d'identifier si le son émis par une source quelconque, est normal ou anormal,\n","        alors qu’un son qualifié d’anormal n’est pas connu auparavant.\n","      \n","        Cette détection d’anomalie non supervisée est utilisée de manière très intuitive par l’homme, dans tout domaine de la maintenance :\n","        par exemple dans notre quotidien, si nous entendons un bruit suspect lors de l’utilisation de notre voiture,\n","        nous la portons au garage pour diagnostic et réparation. Dans l’industrie, les équipes de maintenance font des tournées de contrôle afin de vérifier,\n","        visuellement mais aussi par le son, que le comportant des machines surveillées est normal.\n","        \n","        >*Le son et la détection de ces dérives est donc une première source d’information importante dans le diagnostic de panne.*\n","\n","        A l’ère de la **smart factory** et de la 4ème révolution industrielle (« l’Usine 4.0 »), la **détection automatique des défaillances** par analyse sonore\n","        par intelligence artificielle est une technologie essentielle pour automatiser ces contrôles  \n","        \n","        L’apparition d’anomalies et d’incidents sur les composants peut avoir des conséquences néfastes importantes pour les exploitants et les mainteneurs telles que la perte de production,\n","        l’interruption de service, les blessures physiques ou encore l’augmentation des coûts de maintenance liée au remplacement de pièces qui aurait pu être évité.\n","        Ainsi, la **détection précoce** de ces anomalies de fonctionnement peut éviter des dommages plus importants et réduire les coûts de réparation et d'entretien.\n","        Une détection précoce et fiable des anomalies permet en outre d’identifier l’état d’une machine ou d’un système qui se dégrade,\n","        permettant ainsi le développement et l’implantation de **maintenance prédictive**, plutôt qu’une maintenance préventive qui coûte parfois très cher.\n","\n","        La surveillance acoustique a pour ultime avantage le caractère **bon marché** du matériel, ce qui facilite grandement le **déploiement à grande échelle** de cette méthode.\n","\n","        Le principal défi de cette tâche est de détecter des sons anormaux, alors qu’ils inconnus.\n","        En effet, dans les usines du monde réel, les sons anormaux réels se produisent rarement et sont très divers. Par conséquent,\n","        il est impossible de créer et/ou de collecter délibérément des modèles exhaustifs de sons anormaux. Cela signifie que nous devons **détecter des sons anormaux inconnus** qui n'ont jamais été observés.\n","        Ce point est l'une des principales différences entre l'ASD pour les équipements industriels et les tâches de classification supervisées,\n","        qui eux détectent les sons anormaux déjà définis et connus, tels que les coups de feu ou les pleurs d'un bébé.\n","\n","          >*Ce projet se situe donc bien dans le domaine de la détection d’anomalies non-supervisé.*\n","\n","        Alors que diverses approches de classification supervisées de scènes acoustiques ont été proposées depuis le milieu des années 2010\n","        (‘Anomalous Sound Detection with Machine Learning : A Systematic Review’, E. NUNES, 2021), la détection d'anomalies acoustiques est encore sous-représentée.\n","        En raison de la publication récente d'ensembles de données, la situation s'améliore progressivement.\n","\n","        Actuellement, la majorité des approches de détection d'anomalies acoustiques basées sur des **réseaux de neurones profonds**\n","        et ne nécessitant pas de connaissance de la machine cible sont activement étudiées, notamment les architectures basées sur l’**auto-encodeur**.\n","      \n","      \"\"\")\n","\n","\n","  def projet_progression(self):\n","    st.markdown(\"\"\"\n","      **Acentuer sur l'objectif et l'evolution des méthodes**\n","    \"\"\")\n","    expander_v1 = st.expander(\"V1 : Classification à l'aide de couches denses\",expanded=False)\n","    expander_v2 = st.expander(\"V2 : Detection d'anomalies à l'aide de l'auto-encodeur\",expanded=False)\n","    expander_v3 = st.expander(\"V3 : Detection d'anomalies par encodage puis classification\",expanded=False)\n","\n","    with expander_v1:\n","      st.markdown(\"\"\"### Objectif :\n","  Evaluer la **capacité de classification** des différents individus d’un même type de machine, grâce à un réseau constitué de **couches denses**\n","    \n","        Optimiseur : Adam\n","        Loss       : sparse_categorical_crossentropy\n","        Métrique   : Accuracy = 79% sur les machines ToyCar\"\"\")\n","\n","      st.image(f\"{self.root_path}/images/schema_v1.png\",caption=\"Modèle et résultats de la première itération du projet\")\n","      st.markdown(\"\"\"\n","        ### Bilan :\n","        Une structure simple composée de couches dense permet déjà de séparer les machines sur la base de spectrogrammes\n","      \"\"\")\n","    with expander_v2:\n","      st.markdown(\"\"\"\n","      ### Objectif :\n","        1. Evaluer la capacité de l'autoencodeur pour **capturer l'essentiel de l'information** d'un spectrogramme.\n","        2. Evaluer si l'**erreur de reconstruction** du spectrogramme est une métrique prometteuse pour dtecter les sons anormaux\n","\n","      ### Hypothèse : \n","      Etant donné que l'apprentissage est effectué uniquement sur le jeu de donnée 'normal', les sons anormaux pourraient présenter une erreur de reconstruction \n","      plus élevée (MSE globale entre l'image d'input et l'image d'output du décoder) que les sons normaux.\n","          \n","              Optimiseur : Adamax\n","              Loss       : MSE \n","              Métrique   : RMSE significativement plus importante pour les anormaux (pour 4/8 machines testées)\"\"\")\n","      \n","      # affichage modèle v2\n","      st.image(f\"{self.root_path}/images/model_v2.png\",caption=\"Modèle de la deuxième itération du projet (autoencoder)\")\n","\n","      # affichage tableau et graphique\n","      col1, col2 = st.columns(2)\n","      \n","      with col1:\n","        st.write(\"\")\n","        st.write(\"\")\n","        st.markdown(\"\"\"Resultats des métriques mse/rmse de 10 échantillons pour le type de machine _Toycar_\"\"\")\n","        st.write(\"\")\n","        st.write(self.toycar_test_pred_v2[[\"type_set\",\"classe\",\"type_machine\", \"machine_type_id\",\"mse\",\"rmse\"]].sample(10))\n","\n","      with col2:\n","        anorm_1 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==1)&(self.toycar_test_pred_v2[\"classe\"]==\"anomaly\")][\"rmse\"]\n","        anorm_2 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==2)&(self.toycar_test_pred_v2[\"classe\"]==\"anomaly\")][\"rmse\"]\n","        anorm_3 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==3)&(self.toycar_test_pred_v2[\"classe\"]==\"anomaly\")][\"rmse\"]\n","        anorm_4 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==4)&(self.toycar_test_pred_v2[\"classe\"]==\"anomaly\")][\"rmse\"]\n","\n","        norm_1 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==1)&(self.toycar_test_pred_v2[\"classe\"]==\"normal\")][\"rmse\"]\n","        norm_2 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==2)&(self.toycar_test_pred_v2[\"classe\"]==\"normal\")][\"rmse\"]\n","        norm_3 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==3)&(self.toycar_test_pred_v2[\"classe\"]==\"normal\")][\"rmse\"]\n","        norm_4 = self.toycar_test_pred_v2[(self.toycar_test_pred_v2[\"machine_type_id\"]==4)&(self.toycar_test_pred_v2[\"classe\"]==\"normal\")][\"rmse\"]\n","\n","        hist_data = [anorm_4, norm_4, anorm_3, norm_3, anorm_2, norm_2, anorm_1, norm_1 ]\n","        hist_label = [\"machine_4  -Anormale\", \"machine_4  Normale\",\n","                      \"machine_3  -Anormale\", \"machine_3  Normale\",\n","                      \"machine_2  -Anormale\", \"machine_2  Normale\",\n","                      \"machine_1  -Anormale\", \"machine_1  Normale\"]\n","        colors = ['rgb(400, 0, 200)','rgb(0, 0, 200)', 'rgb(400, 70, 200)','rgb(0, 70, 200)','rgb(400, 160, 200)','rgb(0, 160, 200)','rgb(400, 220, 200)','rgb(0, 220, 200)']\n","        fig = ff.create_distplot(hist_data,hist_label,show_hist=False,bin_size=0, colors=colors)\n","        fig.update_layout(title_text='Densité des RMSE par machine et type de normalité (sous ensemble Toycar)')\n","        fig.update_xaxes(title_text='RMSE')\n","        fig.update_xaxes(range=[0.04, 0.19])\n","        # fig.update_yaxes(title_text='densité')\n","        st.plotly_chart(fig)\n","\n","      st.markdown(\"\"\"\n","        ### Bilan :\n","        **L'erreur de reconstruction de l'autoencoder** permet de séparer les sons normaux des sons anormaux.\n","        Cependant un **traitement plus fin ou plus spécifique** semble nécessaire pour certaines machines, dont les sons normaux/anormaux sont encore indiscernables\n","\n","      \"\"\")\n","\n","\n","\n","    with expander_v3:\n","      st.markdown(\"\"\"### Objectif :\n","  1. Affiner les caractérisation (individualisation) des machines et des individus   *  --> fonction de perte personnalisée*\n","  2. Optimiser la détection des anomalies par type machine   *  --> ACP puis LOF*\n","\n","### Hypothèse :\n","  La partie *encoder* va être utilisée pour capturer la spécificité des machines.\n","\n","  1. Grâce à une **fonction de perte personnalisée** :\n","    - forcer l'identification des **points communs** entre deux spectrogrammes d'une **machine identique**,\n","    - forcer l'identification des **différences** sur les spectrogrammes de 2 machines **différentes**\n","\n","\n","  2. Grâce à une **ACP** suivie d'un **LOF** :\n","    - **Capturer l'essentiel** de l'information dans un **espace réduit** _(à 3 dimensions)_ pour permettre...\n","    - **L'optimisation par type de machine** de la détection d'anomalie _(en fonction de la dispersion des différents nuages de points)_\n","\n","\n","    Optimiseur : Adamax\n","    Loss       : Personnalisée grâce à un générateur de batch de 'triplets de spectrogrammes'\n","    Métrique   : Sensibilité et spécificité de détection\n","    \"\"\")\n","      \n","\n","      st.image(f\"{self.root_path}/images/model_v3.png\",caption=\"schéma de la troisième itération du projet : encodage puis classification\")\n","      st.markdown(\"\"\"\n","      ### Bilan : [_i_](https://fr.wikipedia.org/wiki/Sensibilit%C3%A9_et_sp%C3%A9cificit%C3%A9#/media/Fichier:Sensibilit%C3%A9_et_Sp%C3%A9cificit%C3%A9.svg)\n","      - ** Sensibilité volatile** selon les _types de machine_ : \n","        - _ToyConveyor_ : 14% de détection _vs_ _Valve_ : 96% de détection !\n","        - en moyenne autours de **75% de detection d'anomalies**.\n","\n","\n","      - **Bonne spécificité** de la détection d'anomalie : **15% de fausses alarmes** seulement !\n","\n","    \n","\n","      \"\"\")\n","\n","      \n","\n","  def projet_resultats(self):\n","    st.markdown(\"\"\"\n","      Pointer vers le menu **Résultats & Perspectives**\n","    \"\"\")\n","\n","  def les_donnees(self):\n","    st.write(\"Les données issues du dataset [KAGGLE](https://www.kaggle.com/daisukelab/dc2020task2) sont constituées de fichiers au format _wav_.\" \n","    \"\\nDiverses manipulations de ces données permettent de mieux cerner où sera le travail de modélisation\")\n","     \n","    #sous_menu = [\"Première exploration de données\",\"Visualisation des données audio\",\"Visualisation temps-fréquence\"]\n","    #ss_menu = st.selectbox(\"\",sous_menu )\n","    st.header(self.chapitre_choice)\n","\n","    if self.chapitre_choice==self.sous_menu_donnees[1]:\n","      self.raw_data()\n","    elif self.chapitre_choice==self.sous_menu_donnees[0]:\n","      self.distribution_data()\n","    elif self.chapitre_choice == self.sous_menu_donnees[2]:\n","      self.pipeline()\n","\n","  def pipeline(self):\n","    #st.subheader(\"Représentation en temps - fréquence à l'aide de spectrogramme\")\n","    st.write(\n","    '''\n","    La **représentation temps-fréquence consiste à extraire les composantes fréquentielles du signal au cours du temps**.\n","     Les transformations de **fourier** sous-jacentes travaillent sur des fenêtres temporelles du signal, permettant d'analyser chaque sous fenêtre. \n","     Si des différences fréquentielles au cours du temps ont lieu dans le signal, elles apparaissent alors dans le **spectrogramme**, représentation matricielle des composantes fréquentielles en colonne, au cours du temps: les lignes \n","\n","    ''')\n","\n","    for m in self.selected_machine:\n","      if 'expand_'+m not in st.session_state:\n","        st.session_state['expand_'+m] = False\n","\n","      if 'sample_normal_'+m not in st.session_state:\n","          st.session_state['sample_normal_'+m]  = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='non')].sample(1).fichier.values[0]\n","      file1 = st.session_state['sample_normal_'+m]\n","\n","      if 'sample_anormal_'+m not in st.session_state:\n","          st.session_state['sample_anormal_'+m] = st.session_state['sample_anormal_'+m] = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='oui')].sample(1).fichier.values[0]\n","      file2 = st.session_state['sample_anormal_'+m]\n","\n","      my_expander = st.expander(label='visualisation signaux machine '+ m, expanded = st.session_state['expand_'+m])\n","      \n","      with my_expander:\n","        fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows=2, ncols=2, sharex=True,figsize=(18,6),gridspec_kw={'height_ratios': [1, 2]})\n","        self.plot_audio(file1,fig,ax1)\n","        ax1.set(title='signal '+m+' normal')\n","      \n","        self.plot_audio(file2,fig,ax2)\n","        ax2.set(title='signal '+m+' anormal')\n","\n","        img,spectro1=self.plot_spectrogram(file1,ax3)\n","        ax3.set(title='spectrogramme')\n","       \n","        _,spectro2=self.plot_spectrogram(file2,ax4)\n","        ax4.set(title='spectrogramme')\n","\n","        cbar_ax = fig.add_axes([0.135, 0.00, 0.75, 0.02]) #0.09, 0.06, 0.84, 0.02\n","        fig.colorbar(img, cax=cbar_ax, orientation=\"horizontal\")\n","        st.write(fig)\n","    \n","  def distribution_data(self):\n","    st.write('''\n","    Les fichiers du dataset sont fournis dans différents répertoires, classés par _**type de machine**_, et jeu d'_**apprentissage**_ ou de _**test**_. Une dataframe dans laquelle les données ont été _dénormalisées_ a été constituée pour faciliter la manipulation. \n","    Le dataset est constitué de près de 31 000 enregistrements pour 6 types de machines: 86h d'enregistrement et près de 10 Gb de données.  Chaque type de machine comporte 3 ou 4 machines différentes. \n","    ''')\n","      \n","    if 'check_data' not in st.session_state:\n","      st.session_state.check_data = False\n","    check_data = st.checkbox(\"afficher toutes les données\",key='check_data',help='affiche seulement 20 lignes aléatoires de la dataframe, ou la totalité des lignes')\n","\n","    if 'df_samples' not in st.session_state:\n","      st.session_state.df_samples = np.random.choice(len(self.df),20,False)\n","\n","    if check_data:\n","      st.write(self.df)\n","    else: \n","      valid_index = [i for i in st.session_state.df_samples if i<len(self.df) ]\n","      st.write(self.df.iloc[valid_index].sort_values('type'))\n","\n","    st.subheader(\"répartition des fichiers et de leurs caractéristiques\")\n","    \n","    abs = st.checkbox(\"affichage absolu\",help=\"cliquez sur les figures pour afficher les détails\")\n","    lab_type= 'label+percent entry'\n","    if abs:\n","      lab_type='label+value'\n","\n","    col1,col2 = st.columns(2)\n","    color_sequence = self.px_color\n","    color_map={}\n","    color_map['set']='#FFFFFF'\n","    for i, m in enumerate(self.df.type.unique()):\n","      color_map[m]=color_sequence[i]\n","    \n","\n","    self.df_train.sort_values('machine')\n","    self.df_test.sort_values('machine')\n","    fig2 = px.sunburst(self.df_train,path=['set','type','machine','anomalie'], color = 'type',color_discrete_map=color_map, title=\"données d'apprentissage\")\n","    fig2.update_traces(textinfo=lab_type)\n","    fig2.update_layout(height=800,uniformtext=dict(minsize=15,mode='hide'),margin = dict(t=50, l=0, r=50, b=0), title_font_size=24)\n","    \n","    col1.plotly_chart(fig2,use_container_width=True)\n","  \n","    fig3 = px.sunburst(self.df_test,path=['set','type', 'machine','anomalie'], color = 'type',color_discrete_map=color_map,title=\"répartition des données de test\")\n","    fig3.update_layout(height=800,uniformtext=dict(minsize=15,mode='hide'),margin = dict(t=50, l=50, r=0, b=0),title_font_size=24)\n","    fig3.update_traces(textinfo=lab_type)\n","    col2.plotly_chart(fig3,use_container_width=True)\n","\n","\n","  def raw_data(self):\n","\n","    st.write('''\n","    Les fichiers sont enregistrés au **format _wav_**, de durée d'environ **10s**. La fréquence d'échantillonnage est identique pour tous les fichiers:  **16kHz**.\n","    \\nCette page permet, à gauche, d'**écouter et de visualiser** des sons pour laquelle la machine ne présente pas d'anomalie, et à droite, des sons présentant une anomalie.\n","    ''')\n","    st.caption(\"Cliquez sur la machine que vous souhaitez étudier pour afficher les informations correspondantes. Vous pouvez sélectionner des machines supplémentaires sur le menu de droite.\")\n","\n","    for m in self.selected_machine:\n","      if 'expand_'+m not in st.session_state:\n","        st.session_state['expand_'+m] = False\n","\n","      my_expander = st.expander(label='visualisation signaux machine '+ m, expanded = st.session_state['expand_'+m])\n","\n","      with my_expander:\n","        col1,col2 = st.columns(2)\n","        col1.write(\"son normal\")\n","     \n","        if 'sample_normal_'+m not in st.session_state:\n","          st.session_state['sample_normal_'+m]  = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='non')].sample(1).fichier.values[0]\n","        file1 = st.session_state['sample_normal_'+m]\n","\n","        col1.caption(file1)\n","        col1.audio(open(file1, 'rb').read(),format='audio/wav')\n","\n","        col2.write(\"son anormal\")\n","\n","        if 'sample_anormal_'+m not in st.session_state:\n","          st.session_state['sample_anormal_'+m] = st.session_state['sample_anormal_'+m] = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='oui')].sample(1).fichier.values[0]\n","        file2 = st.session_state['sample_anormal_'+m]\n","\n","        col2.caption(file2)\n","        col2.audio(open(file2, 'rb').read(),format='audio/wav')\n","\n","        fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True,figsize=(18,3))\n","        ax[0].set(title=m+' normal')\n","        ax[0].set_ylim(-0.45,0.45)\n","        self.plot_audio(file1,fig,ax[0])\n","        ax[1].set(title=m+' anormal')\n","        ax[1].set_ylim(-0.45,0.45)\n","        img = self.plot_audio(file2,fig,ax[1])\n","        st.write(fig)\n","\n","  def modelisation(self):\n","    st.header(\"Modélisation\")\n","\n","    if self.chapitre_choice==self.modelisation_chapters[0]:\n","      self.model_intro()\n","    elif self.chapitre_choice==self.modelisation_chapters[1]:\n","      self.model_loss()\n","    elif self.chapitre_choice==self.modelisation_chapters[2]:\n","      self.model_architecture()\n","    elif self.chapitre_choice==self.modelisation_chapters[3]:\n","      self.model_scatter()\n","    elif self.chapitre_choice==self.modelisation_chapters[4]:\n","      self.model_anomaly()\n","    else:\n","      self.model_detection()\n","\n","  def model_intro(self):\n","\n","    st.subheader(\"principes & objectifs:\")\n","    st.markdown(\n","    \"\"\"\n","    La modélisation va consister à **analyser les spectrogrammes**. Nous nous sommes posé plusieurs types de questions pour converger au cours de **différentes itérations** vers l'objectif du projet en lui-même:\n","      - permettent-ils de **discriminer** chaque type de **machine** ?\n","      - permettent-ils de **discriminer chaque machine différente**, à l'intérieur de leur propre groupe et parmi tous les types? \n","      - peut-on **distinguer** (et donc classifier) **les sons normaux et anormaux**?\n","      - et enfin, cette classification peut-elle être menée sous la **forme non supervisée**? \n","    \"\"\"\n","    )\n","    st.subheader(\"processus mis en place:\")\n","\n","    st.write('''\n","    On commence par **encoder les spectrogrammes** (_image embedding_), en recherchant 2 objectifs:\n","    - réduire leur **taille**\n","    - **construire un espace discriminant**: l'espace des features construit doit maximiser l'écart entre les différentes machines, et minimiser l'écart entre les différents échantillons d'une même machine, afin de constituer des **grappes homogènes**.\n","    Nous visons à ce que les **anomalies se détachent de ces grappes**, afin de mettre en oeuvre des **techniques de détection d'anomalies et d'outliers**. \n","    \n","    L'apprentissage est réalisé grâce à un **générateur**, qui produit aléatoirement des batchs de triplets de 2 spectrogrammes d'une même machine et 1 spectrogramme d'une autre machine.\n","    Il est réalisé sur la totalité du dataset d'entraînement, en moins de 3h (batch: 12 triplets de spectrogrammes, 40 epochs, nb steps: nb_moyens d'images par machine/ taille du batch)\n","    \n","    Cette première étape permet de passer d'une **matrice de 512*256** flottants à un **vecteur de 128** flottants.\n","    \n","    Afin de réduire encore la complexité du problème de détection, on ajoute après cette représentation continue (_embedding_), une phase **d'Analyse en Composantes Principales**,\n","     afin de projeter nos nouvelles données créées dans un nouvel espace où les dimensions sont les plus décorrélées possibles. \n","\n","    Notre process complet permet donc de passer d'un son de 10s, représenté par **160 000 points** (10s * 16kHz) **à une représentation en 3 dimensions** seulement, permettant de les discriminer visuellement.\n","    Le dataset de 8 Go compressé est représenté par un fichier csv de 3Mo ! \n","    Cet encodage se réalise en 10ms en moyenne sur de Google engine GPU, et 1,5 ms sur les TPU de Google, grâce à un pipeline TensorFlow:  cela permet largement d'envisager une analyse en temps réel.\n","    ''')\n","\n","  def en_travaux(self):\n","    st.subheader(\"en construction ! \")\n","    st.markdown(\":construction:\")\n","\n","  def model_architecture(self):\n","    st.write('''\n","    Pour minimiser la **fonction de _loss_** précédemment décrite, nous avons besoin de calculer, \n","    à chaque itération de l'apprentissage, les distances 2 à 2 des vecteurs de sortie d'un **triplet de spectrogrammes**, \n","    constitué par 2 spectrogrammes de la même famille, et un 3ème spectrogramme d'une autre famille.\n","\n","    Le **réseau convolutif** est par conséquent alimenté par **batch de triplets de spectrogrammes**. Ces batchs sont construits grâce à un **générateur**.\n","  \n","    ''')\n","  #st.write(encoder.summary())\n","    dot_img_file = '/tmp/model_1.png'\n","    tf.keras.utils.plot_model(self.encoder, to_file=dot_img_file, show_shapes=True,show_dtype=False,show_layer_names=False,expand_nested=False,dpi=60,rankdir = 'TB') #'TB'\n","\n","    col1,col2 = st.columns((1,2))\n","    col1.subheader(\"structure du modèle de CNN\")\n","    col1.subheader(\"\")\n","    col1.image(dot_img_file)\n","    col2.subheader(\"générateur\")\n","    col2.write(\"\")\n","    file = self.root_path+\"images/spectro-triplets.png\"\n","    col2.image(file,use_column_width=True)\n","\n","    st.subheader(\"Apprentissage\")\n","    st.write('''\n","    L'apprentissage est effectué en 2 temps, en faisant varier le learning rate de $5.10^-4$ à $10^-5$.\n","    Pour ces 2 étapes d'apprentissage, 40 epochs de 675 batch, soit 27 000 triplets de spectrogrammes parmi $20 000^3$ possibles, sont utilisés à chaque apprentissage.\n","\n","    Il est effectué approximativement en 3h sur un notebook colab pro, disposant de GPU et de 25 Go de RAM. Rappelons que le réseau est très gros: 4 000 000 de paramètres à entraîner.\n","    \n","    ''')\n","    st.caption('NB: Des améliorations dans le processus de calcul des spectrogrammes serait à apporter pour alléger ce recours à la RAM.')\n","\n","    col1,col2 = st.columns(2)\n","    col1.image(self.root_path+\"images/apprentissage_phase1.PNG\")\n","    col2.image(self.root_path+\"images/apprentissage_phase2.PNG\")\n","\n","\n","  def model_loss(self):\n","    st.subheader(\"fonction de perte personnalisée: \")\n","    # $\\sum_{\\mathclap{1\\le i\\le 3}} \\Delta_i$\n","    st.write(\"\")\n","    col1,col2,col3 = st.columns((1,1,1))\n","    #col1,col2 = st.columns(2)\n","    file = self.root_path+\"images/kmeans.png\"\n","    col1.image(file)\n","    col2.subheader(\"$\\displaystyle LOSS=\\dfrac{\\delta_1}{\\dfrac{1}{2}(\\delta_2 + \\delta_3 +\\epsilon) }$\") #\n","    file = self.root_path + \"images/distances2.png\"\n","    #col2.image(file)\n","    col3.image(file)\n","\n","    with st.echo():\n","      def loss(y_true, y_pred):\n","        \"\"\"\n","        méthode de caclcul de perte cherchant à minimiser la distance entre les 2 premiers vecteurs,\n","        tout en maximisant leur distance avec le 3eme.\n","\n","        :param y_true: vecteur théorique attndu: non pris en compte\n","        :param y_pred: vecteur calculé\n","        :return: distance moyenne entre les vecteurs du batch\n","        \"\"\"\n","        p1_id1 = y_pred[::3]\n","        p1_id2 = y_pred[1::3]\n","        p2_id1 = y_pred[2::3]\n","        return tf.reduce_mean(normL2(p1_id1, p1_id2)/(1e-8+1/2* normL2(p1_id1, p2_id1) + 1/2* normL2(p1_id2, p2_id1)))\n","\n","    st.write('''\n","    Ce **coût** est construit comme fonction des **distances euclidiennes** $\\delta_1$, $\\delta_2$ et $\\delta_3$ entre 3 vecteurs d'un triplet de points $(p_1,p_2,p_3)$. \n","\n","    Il est totalement indépendant d'une variable cible comme cela peut  être le cas pour une régression ou une classification;\n","    celle-ci n'est d'ailleurs pas définie dans le générateur: nous sommes dans un cas de  _unsupervised_ ou _self_supervised learning_ ?\n","    ''')\n","\n","  def model_scatter(self):\n","    df = tb.get_data(self.root_path+'final_encoded_machine_dataset_noPCA.csv',index=0)\n","    df_train = df[df.set=='train']\n","    #StandardScaler\n","    df_train.iloc[:,5:] = (df_train.iloc[:,5:] - df_train.iloc[:,5:].mean()) / df_train.iloc[:,5:].std()\n","    # pca\n","    n_components=3\n","    pca = PCA(n_components=n_components)\n","    pca.fit(df_train.iloc[:,5:])\n","    df_train = df_train.join(pd.DataFrame(pca.transform(df_train.iloc[:,5:]), columns=['PCA%i' % i for i in range(n_components)], index=df_train.index))\n","   \n","    #scaler = StandardScaler()\n","    #df_train_vector = scaler.fit_transform(df_train_vector)\n","    #df_train = df_train[['fichier','set','type','machine','anomalie']].join(df_train_vector)\n","\n","    st.write('''\n","    L'encodage des spectrogrammes permet de créer **des clusters homogènes** sans dispersion. Les algorithmes de **classification** classiques (kNN, RandomForest, SVM) testés permettent d'obtenir des résultats de classification par \n","    **type de machine ou par machine prometteurs**\n","    - **par type de machine: ** une précision de ** classification >98,5% en moyenne** est obtenue. Quelques confusions notamment entre ToyCar et Valve. La classification par kNN reste efficace même en réduisant l'espace à 2 composantes principales, issues des 128 dimensions de l'encodage.\n","    - **par machine:** une précision de classification **>94 % peut être obtenue sur le jeu de train** mais de l'ordre de 90% sur le jeu de test. Les confusions se situent toujours également autour de la machine ToyCar. Les performances de classification sans ce type de machine sont > à 97,9% avec 10 composantes, et 20 voisins.\n","    \n","    Les matrices de confusion, présentées en bas de page, permettent de comprendre facilement sur quel type de machine se situent les pertes de performances.\n","\n","    ''')\n","\n","    st.subheader(\"représentation des vecteurs de features issues de l'apprentissage\")\n","    color_choice = st.radio(\"coloration des nuages:\",options=(\"type\",\"machine\"),key=\"radio_color\",help=\"les points seront colorés selon votre choix, en fonction du type de la machine, ou de la machine elle-même \")\n","\n","    fig = px.scatter_3d(df_train[df_train.type.isin(self.selected_machine)], x='PCA0', y='PCA1', z='PCA2',\n","              color=color_choice, opacity = 0.6, width=1200, height=1000, title=\"représentation des 3 axes principaux de l'ACP\",color_discrete_sequence=self.px_color)\n","  \n","    fig.update_layout(\n","        title={\n","            'x':0.5,\n","            'y':0.95,\n","            'xanchor': 'center',\n","            'font':{'size':22}})\n","    fig.update_traces(\n","        marker=dict(\n","        size=3,\n","    ))\n","    st.plotly_chart(fig)\n","\n","    col1,col2 = st.columns(2)\n","    col1.subheader(\"classification par type de machine: matrice de confusion\")\n","    col1.image(self.root_path+\"images/confusion_classif_type.png\", caption=\"matrice de confusion classification par type\")\n","    col2.subheader(\"classification par machine: matrice de confusion\")\n","    col2.image(self.root_path+\"images/confusion_classif_machine.png\",caption=\"matrice de confusion classification par machine\")\n","\n","  def model_anomaly(self):\n","\n","    df = tb.get_data(self.root_path+'final_encoded_machine_dataset_noPCA.csv',index=0)\n","    df_train = df[(df.set=='train')& (df.type.isin(self.selected_machine))]\n","    #StandardScaler\n","    df_train.iloc[:,5:] = (df_train.iloc[:,5:] - df_train.iloc[:,5:].mean()) / df_train.iloc[:,5:].std()\n","    # pca\n","    n_components=2\n","    pca = PCA(n_components=n_components)\n","    pca.fit(df_train.iloc[:,5:])\n","\n","    df = df.join(pd.DataFrame(pca.transform(df.iloc[:,5:]), columns=['PCA%i' % i for i in range(n_components)], index=df.index))\n","    \n","    st.subheader(\"représentation des features extraites des données de test:\")\n","    st.write(\"L'encodage, entraîné uniquement sur les données du set _train_, permet d'extraire des informations très intéressantes pour discriminer les anomalies de la majorité des machines:\")\n","    \n","    for m in df_train.type.unique():\n","      with st.expander(m):\n","        col1,col2= st.columns(2)\n","        for i,mach in enumerate(df[(df.type==m)].machine.unique()):\n","            fig = px.scatter(df[((df.machine == mach)) & (((df.set=='train')&(df.anomalie=='non')) | ((df.set=='test')&(df.anomalie=='oui')))], x='PCA0', y='PCA1',\n","                    color='anomalie', opacity = 0.6, width=700, height=400, title=\"machine \"+mach,color_discrete_sequence=self.px_color)\n","            fig.update_layout(\n","              title={\n","                  'x':0.5,\n","                  'xanchor': 'center',\n","                  'font':{'size':18}},\n","              margin = dict(l=0, r=0, b=0)\n","              )\n","            fig.update_traces(marker=dict(size=5))\n","\n","            col = i%2\n","            if col==1:\n","              with col2:\n","                st.plotly_chart(fig)\n","            else:\n","              with col1:\n","                st.plotly_chart(fig)\n","    st.subheader(\"résultats de classification:\")\n","    st.write('''\n","\n","    En analysant finement les résultats d'une **classification des machines par SVM ou par kNN** par exemple, on remarque que la différenciation entre sons normaux et anormaux est plus marquée lorsque l'on tronque \n","    une très grande majorité des détails issus de la décomposition en composantes principales. Ainsi, en gardant **50% des composantes principales**, un SVM classifie bien les **sons normaux à 95%** dans le jeu de train, et **seulement à 54% dans le jeu de test pour les normaux**, et **28% pour les anormaux**.\n","    En conservant uniquement **2 composantes principales**, ce même SVM classifie les **sons normaux à 90.66% de précision sur les données d'apprentissage**, et généralise à ** 87% sur les données de test normales**, contre **47.2% sur les sons anormaux**\n","\n","    De même, un **classifieur kNN** dont l'apprentissage a été fait uniquement sur des données normales, et testé sur les données normales et anormales montre des résultat similaires. ''')\n","\n","    st.success('''\n","    Notre objectif semble rempli:  **les classifieurs semblent en difficulté pour reconnaître avec fiabilité les machines lorsque celles-ci présentent une anormalité**, alors que la classification sur les \n","    données de test normales présentent des performances conformes au jeu de validation issu du jeu d'apprentissage.\n","    C'était bien le but de la démarche d'encodage.  \n","    \n","    **Nous avons donc réussi à développer un modèle encodage qui permet de construire un nouvel espace de représentions discriminant les sons normaux des sons anormaux.**\n","    \n","    Les algorithmes **de détection non supervisée d'anomalies** peuvent maintenant être étudiés pour répondre à l'objectif complet du projet.\n","    \n","    ''')\n","    col1, col2 = st.columns(2)\n","    with col1:\n","      col1.subheader(\"matrice de confusion sur données de test normales\")\n","      col1.image(self.root_path+\"images/confusion_machine_test_normale.png\")\n","    with col2:\n","      col2.subheader(\"matrice de confusion sur données de test anormales\")\n","      col2.image(self.root_path+\"images/confusion_machine_test_anormale.png\")\n","\n","    \n","  def model_detection(self):\n","    st.subheader(\"détection non supervisée des anomalies\")\n","    st.write('''\n","    La stratégie de détection des anomalies est basée sur des dérivés d'algorithmes de classification. Ces algorithmes étudient la probabilité qu'un point non connu jusqu'ici, appartienne à la même distribution qu'un ensemble de points connus.\n","\n","    Pour notre projet, nous avons plus particulièrement étudié les algorithmes de **LOF: _Local Outlier Factor_** et **_One-Class SVM_**\n","    mais il en existe bien d'autres. \n","    \n","    En analysant les points dans leur ensemble, on constate que **les espaces\n","    de sons anormaux chevauchent parfois les espaces de sons normaux d'autres machines**. \n","    Nous avons donc choisi d'étudier la **détection non supervisée d'anomalie machine par machine** afin de ne pas être perturbés par ce phénomène.\n","    ''')\n","    st.info('''\n","    **Remarque:** Ce fonctionnement représente mieux **l'application industrielle** qui pourrait en être faite: \n","    on entraîne un modèle de _LOF_ ou de _OSVM_ sur des données de machine normale\n","    et on cherche à détecter les anomalies sur cette même machine.''')\n","\n","    st.subheader('**OcSVM: One Class SVM**')\n","    st.markdown('''\n","    Le **_One Class SVM_** est un algorithme de recherche non supervisée d'anomalies, très largement utilisé.\n","    La famille des _machines à vecteur supports_ permet de calculer **une frontière de décision** dans un espace multidimensionnel, permettant de **classer tout nouveau point comme appartenant à une région, ou une autre**.\n","    \n","    Dans le cas du **_OSVM_**, l'algorithme **apprend à définir une région unique** à partir des points de l'entraînement. \n","    Si un nouveau point testé **n'appartient pas à cette région**, il est considéré comme **_anomalie_**.\n","    L'OSVM que nous avons entraîné pour chaque machine repose sur un **noyau _RBF_**. \n","    \n","    Ses performances dépendent principalement des paramètres ** $gamma$ ** et ** $nu$ **\n","    ''')\n","    st.image(self.root_path+'images/reglage-gamma-OSVM3.png', caption=\"exemple de contours des régions apprises suivant les paramètres gamma  (de gauche à droite) et nu (les différentes régions dessinées) \")\n","    #st.image(self.root_path+'images/reglage-gamma-OSVM2.png', caption=\"exemple de contours des régions apprises suivant les paramètres gamma  (de gauche à droite) et nu (les différentes régions dessinées) \")\n","    \n","    st.subheader('**LOF: Local Outlier Factor**')\n","    st.write('''\n","    Le _LOF_ est un algorithme de détection d'anomalie non supervisé, qui consiste à **mesurer la différence de densité autour d'un nouveau point par rapport à ses voisins**, connus et normaux. \n","    \n","    Un nouveau point, situé au milieu d'autres points connus lors de l'entraînement, sera supposé appartenir à ce même ensemble de points normaux, alors qu'un nouveau point apparaissant très éloigné d'un nuage de point connu sera supposé être une anomalie.\n","    \n","    Chaque **nouveau point** présenté au modèle se voit donc gratifié **d'un score** d'appartenance à l'ensemble des points normaux. \n","    Un **seuillage de ce score permet de le classer comme _normal_ ou _anormal_ **. \n","    Ce seuillage permettant la classification comme anomalie dépend d'un paramètre appelé **_contamination_**.     \n","    ''')\n","    col1,col2 = st.columns(2)\n","    with col1:\n","      st.image(self.root_path+'images/LOF_scoring1.PNG', caption=\"exemple de scores _LOF_ sur des données normales/anormales séparables \")\n","    with col2:\n","      st.image(self.root_path+'images/LOF_scoring2.PNG', caption=\"exemple de scores _LOF_ sur des données normales/anormales difficilement séparables\")\n","\n","   \n","    st.info('''\n","    Nos travaux ont consisté à tester ces algorithmes et **optimiser leurs hyperparamètres** afin d'obtenir des **résultats optimaux de détection des anomalies**. \n","    Pour cela, des tests de grilles de paramètres (__GridSearchCV__) ont permis de trouver les meilleurs compromis entre **_sensibilité_** \n","    (détection de vraies anomalies) et **_spécificité_** (détection de vrais signaux normaux). \n","\n","    La maximisation de l'_aire sous la courbe_ (**AUC**) permet de synthétiser ce compromis _sensibilité vs spécificité_\n","\n","    ''')\n","\n","  def resultats(self):\n","    st.header(\"Résultats\")\n","    result_LOF = tb.get_data_LOF()\n","    result_LOF = result_LOF.loc[result_LOF.type.isin(self.selected_machine)]\n","    # result_LOF = result_LOF.loc[result_LOF.machine.isin(self.selected_lachines)]\n","    result_SVM =  tb.get_data_SVM()\n","    result_SVM = result_SVM.loc[result_SVM.type.isin(self.selected_machine)]\n","\n","    seuil = st.sidebar.select_slider('contrôle de la sensibilité',options=range(len(result_LOF.contamination.unique())), key='seuil')\n","    contamination = result_LOF.contamination.unique()[seuil]\n","    nu = result_SVM.nu.unique()[seuil]\n","\n","    gp_LOF = result_LOF.groupby('contamination').mean()\n","    gp_LOF['algo']='LOF'\n","    gp_SVM = result_SVM.groupby('nu').mean()\n","    gp_SVM['algo']='SVM'\n","    test = pd.concat([gp_LOF,gp_SVM],ignore_index=True)\n","     \n","    col1, col2, col3 = st.columns((2,4,1))\n","\n","    res_SVM = result_SVM.loc[result_SVM.nu==nu]\n","    res_SVM_aggreg = res_SVM.groupby(['nu']).mean()\n","\n","    res_LOF = result_LOF.loc[result_LOF.contamination==contamination]\n","    res_LOF_aggreg = res_LOF.groupby(['contamination']).mean()\n","\n","    fig = px.line(test, x=\"sensibilite\", y=\"specificite\", color='algo',color_discrete_sequence=self.px_color)\n","    fig.update_layout(height=300,margin = dict(t=0, l=0, r=50, b=0), title_font_size=4)\n","    fig.update_traces(line=dict( width=3))\n","    fig.add_vline(x=res_LOF_aggreg.sensibilite.iloc[0], line_width=2, line_dash=\"dash\", line_color=self.px_color[2])\n","    fig.add_hline(y=res_LOF_aggreg.specificite.iloc[0], line_width=2, line_dash=\"dash\", line_color=self.px_color[2])\n","    col2.write(fig)\n","\n","    col1.write(' - **LOF**  : taux de contamination de {:.2%} \\n   - **sensibilité: {:.2%}**\\n   - **spécificité: {:.2%}**'.format(contamination,res_LOF_aggreg.sensibilite.iloc[0],res_LOF_aggreg.specificite.iloc[0]))\n","    col1.write(' - **OcSVM**: nu de {:.3f} \\n   - **sensibilité: {:.2%}**\\n   - **spécificité: {:.2%}**'.format(nu,res_SVM_aggreg.sensibilite.iloc[0],res_SVM_aggreg.specificite.iloc[0]))\n","      \n","    col1,col2 = st.columns(2)\n","    with col1:\n","        st.subheader(\"détection par LOF\")\n","       \n","        x = [[],[]]\n","        for t in result_LOF['type'].unique():\n","          sous_cat = result_LOF[result_LOF['type']==t].machine.unique()\n","          x[0].extend([t for i in range(len(sous_cat))])\n","          x[1].extend(sous_cat)\n","\n","        fig = go.Figure(go.Bar(x=x, y=res_LOF.specificite, name='spécificité',marker={'color': self.px_color[2]}))\n","        fig.add_trace(go.Bar(x=x, y=res_LOF.sensibilite, name='sensibilité',marker={'color': self.px_color[0]})) #6\n","\n","        fig.update_xaxes(categoryorder='category ascending')\n","        fig.update_layout(height=200,margin = dict(t=30, l=0, r=50, b=0), title_font_size=4)\n","        fig.update_layout(\n","                  title={\n","                      'x':0.5,\n","                      'xanchor': 'center',\n","                      'font':{'size':18}},)\n","        st.write(fig)\n","\n","        df_agg_error =  res_LOF.groupby('type').agg({'sensibilite': ['mean', 'min', 'max'],'specificite':['mean','min','max']})\n","        df_agg_error['sensibilite']['min'] = df_agg_error['sensibilite']['mean']-df_agg_error['sensibilite']['min']\n","        df_agg_error['sensibilite']['max'] = df_agg_error['sensibilite']['max']-df_agg_error['sensibilite']['mean']\n","        df_agg_error['specificite']['min'] = df_agg_error['specificite']['mean']-df_agg_error['specificite']['min']\n","        df_agg_error['specificite']['max'] = df_agg_error['specificite']['max']-df_agg_error['specificite']['mean']\n","\n","        fig2 = go.Figure()\n","        fig2.add_trace(go.Bar(\n","            name='specificite',\n","            x=df_agg_error.index, y=df_agg_error['specificite']['mean'],\n","            marker={'color': self.px_color[2]},\n","            error_y=dict(\n","              type='data',\n","              symmetric=False,\n","              array=df_agg_error[('specificite','max')],\n","              arrayminus=df_agg_error[('specificite','min')])\n","        ))\n","        fig2.add_trace(go.Bar(\n","            name='sensibilité',\n","            x=df_agg_error.index, y=df_agg_error['sensibilite']['mean'],\n","            marker={'color': self.px_color[0]},#6\n","            error_y=dict(\n","              type='data',\n","              symmetric=False,\n","              array=df_agg_error[('sensibilite','max')],\n","              arrayminus=df_agg_error[('sensibilite','min')])\n","        ))\n","        fig2.update_layout(barmode='group',height=200,margin = dict(t=30, l=0, r=50, b=0), title_font_size=4 )\n","        fig2.update_xaxes(categoryorder='category ascending')\n","        col1.write(fig2)\n","\n","    with col2:\n","        st.subheader(\"détection par OcSVM\")\n","\n","        x = [[],[]]\n","        for t in result_SVM['type'].unique():\n","          sous_cat = result_SVM[result_SVM['type']==t].machine.unique()\n","          x[0].extend([t for i in range(len(sous_cat))])\n","          x[1].extend(sous_cat)\n","\n","        \n","        fig = go.Figure(go.Bar(x=x, y=res_SVM.specificite, name='spécificité',marker={'color': self.px_color[2]}))\n","        fig.add_trace(go.Bar(x=x, y=res_SVM.sensibilite, name='sensibilité',marker={'color': self.px_color[1]})) #6\n","\n","        fig.update_xaxes(categoryorder='category ascending')\n","        fig.update_layout(height=200,margin = dict(t=30, l=0, r=50, b=0), title_font_size=4)\n","        fig.update_layout(\n","                  title={\n","                      'x':0.5,\n","                      'xanchor': 'center',\n","                      'font':{'size':18}},)\n","        st.write(fig)\n","\n","        df_agg_error =  res_SVM.groupby('type').agg({'sensibilite': ['mean', 'min', 'max'],'specificite':['mean','min','max']})\n","        df_agg_error['sensibilite']['min'] = df_agg_error['sensibilite']['mean']-df_agg_error['sensibilite']['min']\n","        df_agg_error['sensibilite']['max'] = df_agg_error['sensibilite']['max']-df_agg_error['sensibilite']['mean']\n","        df_agg_error['specificite']['min'] = df_agg_error['specificite']['mean']-df_agg_error['specificite']['min']\n","        df_agg_error['specificite']['max'] = df_agg_error['specificite']['max']-df_agg_error['specificite']['mean']\n","\n","        fig2 = go.Figure()\n","        fig2.add_trace(go.Bar(\n","            name='specificite',\n","            x=df_agg_error.index, y=df_agg_error['specificite']['mean'],\n","            marker={'color': self.px_color[2]}, \n","            error_y=dict(\n","              type='data',\n","              symmetric=False,\n","              array=df_agg_error[('specificite','max')],\n","              arrayminus=df_agg_error[('specificite','min')])\n","        ))\n","        fig2.add_trace(go.Bar(\n","            name='sensibilité',\n","            x=df_agg_error.index, y=df_agg_error['sensibilite']['mean'],\n","            marker={'color': self.px_color[1]}, #6\n","            error_y=dict(\n","              type='data',\n","              symmetric=False,\n","              array=df_agg_error[('sensibilite','max')],\n","              arrayminus=df_agg_error[('sensibilite','min')])\n","        ))\n","        fig2.update_layout(barmode='group',height=200,margin = dict(t=30, l=0, r=50, b=0), title_font_size=4 )\n","        fig2.update_xaxes(categoryorder='category ascending')\n","        col2.write(fig2)\n","\n","    st.header(\"Perspectives\")\n","    st.subheader(\"Détection d'anomalies\")\n","    st.write('''\n","    - meilleure **utilisation des ressources matérielles** (TPU pour créer les spectrogrammes en mois de 1,5 ms et GPU pour entraînement)\n","    - réseau d'encodage\n","      - optimiser le **réseau d'encodage**: nombre et taille des couches, dimensions de sorties, résolution du spectrogramme\n","      - utiliser les **RNN** pour encoder \n","      - optimiser la **structuration des données** pour l'apprentissage du embedding / optimiser la **mémoire** pour l'apprentissage (25 Go nécessaires aujourd'hui)\n","      - optimiser et **approfondir l'apprentissage spécifiquement** autour de quelques machines ?\n","       balance des classes, random undersampling/oversampling car la spécificité semble liée à la distribution des machines dans le set de train (valve02, ? \n","    - détection d'anomalies\n","      - utilisation de la détection en **streaming**, sur des périodes plus courtes \n","      - aller plus loin dans le choix et l'optimisation d'**algorithmes de détection d'anomalies** \n","    ''')\n","    st.subheader(\"Application réelle\")\n","    st.write('''\n","    - transposition du modèle sur d'autres sons issus d'**autres environnements**\n","    - **exploitation dans le cadre d'une supervision d'installations**\n","    ''')\n","    #\n","\n","  def update_samples(self):\n","    st.session_state.df_samples = np.random.choice(len(self.df),20,False)\n","    for m in self.selected_machine:\n","      st.session_state['sample_normal_'+m]  = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='non')].sample(1).fichier.values[0]\n","      st.session_state['sample_anormal_'+m]  = self.df[(self.df['type']==m) & (self.df[\"anomalie\"]=='oui')].sample(1).fichier.values[0]\n","\n","  def a_propos(self):\n","    st.markdown(\"\"\"\n","    # A propos\n","    **pyGoodVibes est un travail collaboratif** réalisé dans le cadre du parcours de formation [DataScientist](https://datascientest.com/formation-data-scientist) avec l’organisme *DataScienTest* et *l’Université Paris La Sorbonne*.\n","    \n","    L’application Streamlit a été conçue à des fins de **présentation du projet de fin d’étude**, sur un jeu de données issu du challenge [DCASE2020](http://dcase.community/challenge2020/task-unsupervised-detection-of-anomalous-sounds), disponible librement sur Kaggle.\n","\n","    Pour toute besoin d’information ou d’utilisation des supports et des résultats de pyGoodVibes, merci de faire parvenir vos demandes directement aux auteurs.\n","    \"\"\")\n","\n","    col1, col2, col3, = st.columns(3)\n","    with col1:\n","      st.image(f\"{self.root_path}images/vignette aurelien.png\")\n","      st.image(f\"{self.root_path}images/vignette christophe.png\")\n","    with col2:\n","      st.write(\"\")\n","      st.write(\"\")\n","      st.markdown(\"\"\"\n","      **Aurélien NANETTE**\n","\n","      _Data Scientist chez LISEA Concessionnaire de la LGV SEA_\n","\n","      [aurelien.nanette@gmail.com](aurelien.nanette@gmail.com)\n","\n","      [https://www.linkedin.com/in/a-nanette/](https://www.linkedin.com/in/a-nanette/)\n","\n","      \"\"\")\n","      st.write(\"\")\n","      st.write(\"\")\n","      st.write(\"\")\n","      st.write(\"\")\n","\n","\n","      \n","\n","      st.markdown(\"\"\"\n","      **Christophe GAUFFRE**\n","      \n","      _Consultant Freelance Vision & IT pour l'industrie_\n","\n","      [contact@c-gauffre.fr](contact@c-gauffre.fr)\n","\n","      [https://www.linkedin.com/in/christophegauffre/](https://www.linkedin.com/in/christophegauffre/)\n","\n","\n","      \"\"\")\n","\n","\n","  def biblio(self):\n","    st.write('''\n","    - [What’s wrong with CNNs and spectrograms for audio processing?](https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd)\n","    - [How to use machine learning for anomaly detection and condition monitoring](https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7)\n","    - [5 Ways to Detect Outliers/Anomalies](https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623)\n","    - [embeddings et représentations continues](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)\n","    - [outlier et distance de mahalanobis](https://towardsdatascience.com/multivariate-outlier-detection-in-python-e946cfc843b3)\n","    - [Useful methods in Python for Detecting Outliers in Data](https://towardsdatascience.com/mastering-outlier-detection-in-python-61d1090a5b08)\n","    - [Unsupervised Anomaly Detection for Univariate & Multivariate Data](https://towardsdatascience.com/anomaly-detection-for-dummies-15f148e559c1)\n","    - [Anomaly Detection, A Key Task for AI and Machine Learning, Explained](https://www.kdnuggets.com/2019/10/anomaly-detection-explained.html)\n","    - [Unsupervised Anomaly Detection in Flight Data Using Convolutional Variational Auto-Encoder](https://www.mdpi.com/2226-4310/7/8/115)\n","    - [knn for anomalies detection](https://towardsdatascience.com/k-nearest-neighbors-knn-for-anomaly-detection-fdf8ee160d13)\n","    - à implémenter tellement c'est simple:[hands-on-unsupervised-learning](https://www.oreilly.com/library/view/hands-on-unsupervised-learning/9781492035633/ch04.html)\n","    - transformer et vecteur d'attention (en complément des RNN): ??\n","    - [BERT models et dérivés (ALBERT,AALBERT) basés sur les Transformer Models](https://medium.com/codex/self-supervised-deep-learning-on-audio-4daf2f2c51f5)\n","    - [self supervised approch, contrastive learning](https://generallyintelligent.ai/understanding-self-supervised-contrastive-learning.html) utilisation de batch normalisation nécessaire!\n","    - [A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data](https://www.researchgate.net/publication/301533547_A_Comparative_Evaluation_of_Unsupervised_Anomaly_Detection_Algorithms_for_Multivariate_Data)\n","    - [Automatic Hyperparameter Tuning Method for Local Outlier Factor, with Applications to Anomaly Detection](https://ieeexplore.ieee.org/abstract/document/9006151)\n","    ''')\n","\n","  def plot_audio(self, file,fig,ax):\n","\n","    audio_data,sr=librosa.load(file)\n","    dt = 1 / sr\n","    t = dt * np.arange(len(audio_data))\n","\n","    librosa.display.waveshow(audio_data, sr=sr, ax=ax)\n","    ax.set_ylabel('amplitude')\n","    ax.set_xlabel('temps (s)')\n","    ax.label_outer()\n","\n","    return fig\n","      \n","  def plot_spectrogram(self, audio_file, ax):\n","    \"\"\"\n","    calcul et affiche le spectrogramme d'un fichier audio\n","    :param audio:signal audio à transformer \n","    :param fe: fréquence d'échantillonnage de l'audio utilisé\n","    :param dt: int>0: résolution temporelle de la STFT\n","    :return: None\n","    \"\"\"\n","    audio_data,sr=librosa.load(audio_file)\n","    dt = 1 / sr\n","    t = dt * np.arange(len(audio_data))\n","\n","    n_fft = 1024\n","    hop_length = int(n_fft/4)\n","    D_highres = librosa.stft(audio_data, n_fft = n_fft, hop_length=hop_length)\n","    S_db = librosa.amplitude_to_db(np.abs(D_highres), ref=np.max)\n","    img = librosa.display.specshow(S_db, x_axis='time', hop_length=hop_length,\n","                                  y_axis='hz' ,ax=ax, cmap='jet')\n","    ax.set_ylabel('Frequence (Hz)')\n","    ax.set_xlabel('temps (s)')\n","    ax.label_outer()\n","\n","    \n","    return img,S_db\n","\n","def main():\n","\n","  st.set_option('deprecation.showPyplotGlobalUse', False)\n","  apptitle = 'pyGoodVibes'\n","  st.set_page_config(page_title=apptitle, page_icon=\":construction_worker:\",layout = \"wide\")\n","  app = my_app()\n","    \n","if __name__ == '__main__':\n","  main()"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"jZ8ZI7FqAJpl"},"source":["## tunneling ngrok-streamlit"]},{"cell_type":"markdown","metadata":{"id":"gvtBF277WWVe"},"source":["### Lancement du tunnel entre ngrok et l'application streamlit"]},{"cell_type":"code","metadata":{"id":"exXftXYqPeyD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633381214616,"user_tz":-120,"elapsed":909,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"476d1390-e44d-401d-ec95-487549e757fd"},"source":["from pyngrok import ngrok\n","\n","!ngrok authtoken 1xYQesOXezZpo4IBed4ePF72elz_6J7QhKowaT1Nuaq2pXBVT  # Christophe\n","\n","# Setup a tunnel to the streamlit port 8501\n","public_url = ngrok.connect(8501)\n","\n","!streamlit run app.py &>/dev/null& # &>/dev/null& rend non bloquant. "],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"]}]},{"cell_type":"markdown","metadata":{"id":"UkZzCEkdNYHH"},"source":["# Lancement du tunnel"]},{"cell_type":"code","metadata":{"id":"4EjGoJjXNdD8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633381220680,"user_tz":-120,"elapsed":273,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"1bf6f5a7-9ab4-4a50-baf0-090960436cb6"},"source":["print(\"RDV à cette adresse:\")\n","print(public_url)"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["RDV à cette adresse:\n","NgrokTunnel: \"http://4465-34-82-44-143.ngrok.io\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"markdown","metadata":{"id":"CoRdn999W-Kj"},"source":["# Terminer le tunnel de Ngrok"]},{"cell_type":"code","metadata":{"id":"y8Eb91aTXNT8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633381205601,"user_tz":-120,"elapsed":265,"user":{"displayName":"Christophe Gauffre","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12891908672068611072"}},"outputId":"4524a221-48b0-4984-d3b2-76bf2a75e664"},"source":["!pgrep streamlit\n","ngrok.kill()"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["481\n","1039\n","1143\n"]}]},{"cell_type":"markdown","metadata":{"id":"jdDA_Nv9_imk"},"source":["# Bibliographie"]},{"cell_type":"markdown","metadata":{"id":"OsxDC93NWoKh"},"source":["**sources intéressantes**\n","- représentations continues de Paul Dechorgnat\n","- [What’s wrong with CNNs and spectrograms for audio processing?](https://towardsdatascience.com/whats-wrong-with-spectrograms-and-cnns-for-audio-processing-311377d7ccd)\n","- [How to use machine learning for anomaly detection and condition monitoring](https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7)\n","- [5 Ways to Detect Outliers/Anomalies](https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623)\n","- [embeddings et représentations continues](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526)\n","- [outlier et distance de mahalanobis](https://towardsdatascience.com/multivariate-outlier-detection-in-python-e946cfc843b3)\n","- [Useful methods in Python for Detecting Outliers in Data](https://towardsdatascience.com/mastering-outlier-detection-in-python-61d1090a5b08)\n","-[Unsupervised Anomaly Detection for Univariate & Multivariate Data](https://towardsdatascience.com/anomaly-detection-for-dummies-15f148e559c1)\n","- [Anomaly Detection, A Key Task for AI and Machine Learning, Explained](https://www.kdnuggets.com/2019/10/anomaly-detection-explained.html)\n","- [Unsupervised Anomaly Detection in Flight Data Using Convolutional Variational Auto-Encoder](https://www.mdpi.com/2226-4310/7/8/115)\n","- [knn for anomalies detection](https://towardsdatascience.com/k-nearest-neighbors-knn-for-anomaly-detection-fdf8ee160d13)\n","- à implémenter tellement c'est simple:[hands-on-unsupervised-learning](https://www.oreilly.com/library/view/hands-on-unsupervised-learning/9781492035633/ch04.html)\n","- transformer et vecteur d'attention (en complément des RNN)\n","- BERT models et dérivés (ALBERT,AALBERT) basés sur les Transformer Models\n","https://medium.com/codex/self-supervised-deep-learning-on-audio-4daf2f2c51f5\n","- [self supervised approch, contrastive learning](https://generallyintelligent.ai/understanding-self-supervised-contrastive-learning.html) utilisation de batch normalisation nécessaire!\n","- [A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data](https://www.researchgate.net/publication/301533547_A_Comparative_Evaluation_of_Unsupervised_Anomaly_Detection_Algorithms_for_Multivariate_Data)\n","\n"]}]}